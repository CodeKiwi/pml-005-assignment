---
title: "PML-005 prediction assignment"
author: "Josh Bondy"
date: "20 September 2014"
output: html_document
---

This is my prediction assignment for <https://class.coursera.org/predmachlearn-005>.

###Background (from assignment)
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). 

###Execuitive summary
The goal of this project is to build a prediction model to correctly classify the quiality of excercises peformed and tracked in the Human Activity Recognition project. Data is available in the form of sensor measurements taken whilst performing barbell lifts. Classification is facilitated by labeled data indicating the diffent way the exercise was performed.

####Import required packages
For this project we will use the **caret** package, this package smoothes over some of the R quirks when it comes to applying machine learning techniques, however the machine learning package selected is the **randomForest** package due to the caret varient iterating too many times. 

```{r}
library(caret)
library(randomForest)
```

####Load data
```{r}
# For local
#setwd("~/Documents/Projects/pml-005-assignment")
#input <- read.csv("pml-training.csv")
#prediction_input <- read.csv("pml-testing.csv") 
set.seed(43)

# For submission
input <- read.csv("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
prediction_input <- read.csv("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
```

####Create training and test sets
Split into training, test and cross validation data sets. It was decided not to use K-Fold cross validation as this was decided to be overkill for the assignment. Using an an approximate 60,20,20 split, this yeilds 12k test cases with approx 3.5k samples in test and cross validation sets.

```{r}
inTrain <- createDataPartition(y=input$classe, p=0.8, list=FALSE)
training_input <- input[inTrain,]
testing <- input[-inTrain,]

inTrain <- createDataPartition(y=training_input$classe, p=0.8, list=FALSE)
training <- training_input[inTrain,]
cross_val <- training_input[-inTrain,]

#Check sizes of sets
dim(training); dim(cross_val); dim(testing)
```

####Clean data
Remove features with low variance and significant NA values
```{r}

# Remove timeseries columns, these facilitated zero test error but would cause failure to generalize
invalidColumns <- c(1,2,3,4,5,6,7)
training <- training[-invalidColumns]
  
# Replace Divide by zero errors and empty cells with NA
training[training == "#DIV/0!" | training == ""] <- NA

# Remove features with greater than 10k NA's 
manyNa <- c()
for (i in 1:ncol(training)){
 if (sum(is.na(training[i])) > 10000){ manyNa <- c(manyNa, i)}
}
training <- training[-manyNa]

#Check sizes of sets
dim(training); dim(cross_val); dim(testing)
```

####Select model parameters
Using the cross validation set train classifiers using a number of different values for ntree and mtry parameters. 

**note* The randomForests library was used in place of the caret wrapper due to the ability to natively modify the ntree and mtry parameters. 

```{r}
ntree_vals <- c(10,100,500)
mtry_vals <- c(5,10,20)
results <- matrix(nrow=length(ntree_vals), ncol=length(mtry_vals)); 
rownames(results) <- ntree_vals; 
colnames(results) <- mtry_vals;
for(i in 1:length(ntree_vals)) {
  for(n in 1:length(mtry_vals)) {
    modelFit <- randomForest(classe~., data=training, ntree=ntree_vals[i], mtry=mtry_vals[n])
    results[i, n] <- mean(predict(modelFit,cross_val) == cross_val$classe)
  }
}
results

```

####Train models
The model is fit using Random Forests, from the parameter selection performed in the previous step we see that 500 for ntrees and 10 for mtry variables gives the optimal accuracy. However 100 trees and 10 features per tree was found to be be the best balance between performance and accuracy.

Given the selected parameters of 500 ntree and 10 mtry the pridicted out of sample error rate is approximately 0.58%. The cross validation actual out of sample error rates is 0.7%

```{r}
modelFit <- randomForest(classe~., data=training, ntree=500, mtry=10)
modelFit

pred_cross_val <- predict(modelFit,cross_val);
cross_val$correct <- pred_cross_val==cross_val$classe
cross_val_error <- mean(cross_val$correct <- pred_cross_val==cross_val$classe) 
cross_val_error

```

####Test model
We can now test the model using the test case, this data has not been used through the model and parameter selection steps to ensure we are not overfitting the data. 

```{r}
pred <- predict(modelFit,testing); 
testing$correct <- pred==testing$classe
table(pred,testing$classe)
mean(testing$correct <- pred==testing$classe)
```

####Final result
The prediction accuracy of the final model was > 99.2%. This is a very positive result with an actual OOB error rate of 0.76%, marginally higher than the expected value of 0.58% but well within acceptible margins.  

**note** The error rate could be greatly reduced by reintroducing the user and time based features however this would reduce the ability for the solution to generalize well.

As you can see from the model plot, the model stabalizes at 100 trees so this parameter can safely be reduced to 100.


```{r}
plot(modelFit)
```

####Predict test data
The final requirement of the assignment is to predict on a test set for submission to the Coursera site. This was completed (and passed 100%) with the function below. With the answers printed for reference.

```{r}
answers <- predict(modelFit,prediction_input); 
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(answers)
answers
```


